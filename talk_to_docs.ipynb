{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines serve for loading the documents. \n",
    "\n",
    "Then the documents are split in chunks.\n",
    "\n",
    "Finally the chunks are embedded and loaded into the vector database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for loading files with different formats or sources\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "def load_pdf(path):\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "def load_url(path):\n",
    "    loader = WebBaseLoader(path)\n",
    "    return loader.load()\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "def load_txt(path):\n",
    "    loader = TextLoader(path)\n",
    "    document = loader.load()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "{'source': 'docs/brief_story.txt'}\n",
      "Once in a vibrant town of Silicoville, nestled between the rolling hills of innovation and the spraw\n"
     ]
    }
   ],
   "source": [
    "# load the first document and explore the object which contains it\n",
    "\n",
    "b = load_txt('docs/brief_story.txt')\n",
    "print(type(b))\n",
    "print(len(b))\n",
    "print(type(b[0]))\n",
    "print(b[0].metadata)\n",
    "print(b[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pdfs and url\n",
    "\n",
    "g = load_pdf('docs/genesis.pdf')\n",
    "\n",
    "gpt4 = load_pdf('docs/gpt4-openai.pdf')\n",
    "\n",
    "w = load_url('https://en.wikipedia.org/wiki/Skynet_(Terminator)')\n",
    "\n",
    "# remove additional info, keep text\n",
    "w[0].page_content = w[0].page_content.split('Download as PDFPrintable')[1].split('Hidden categories')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' version\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nFictional artificial general superintelligence\\nFor other uses of \"Skynet\", see Skynet (d'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 200 characters\n",
    "w[0].page_content[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter by counting tokens using overlap\n",
    "\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "# group all documents and then split them in chunks\n",
    "\n",
    "docs = g\n",
    "docs.extend(w)\n",
    "docs.extend(gpt4)\n",
    "docs.extend(b)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Book of Genesis\\nChapter 1\\nIn the beginning God created heaven, and earth.\\n2And the earth was void and empty, and\\ndarkness was upon the face of the deep; and the\\nspirit of God moved over the waters.\\n3And God said: Be light made. And light\\nwas made.\\n4And God saw the light that it was good; and\\nhe divided the light from the darkness.\\n5And he called the light Day, and the dark-\\nness Night; and there was evening and morning\\none day.\\n6And God said: Let there be a ﬁrmament\\nmade amidst the waters: and let it divide the\\nwaters from the waters.\\n7And god made a ﬁrmament, and divided\\nthe waters that were under the ﬁrmament, from\\nthose that were above the ﬁrmament, and it was\\nso.\\n8And God called the ﬁrmament, Heaven; and\\nthe evening and morning were the second day.\\n9God also said; Let the waters that are under\\nthe heaven, be gathered together into one place:\\nand let the dry land appear. And it was so done.\\n10And God called the dry land, Earth; and\\nthe gathering together of the waters, he called\\nSeas. And God saw that it was good.\\n11And he said: let the earth bring forth green\\nherb, and such as may seed, and the fruit tree\\nyielding fruit after its kind, which may have seed\\nin itself upon the earth. And it was so done.12And the earth brought forth the green\\nherb, and such as yieldeth seed according to its\\nkind, and the tree that beareth fruit, having seed\\neach one according to its kind. And God saw\\nthat it was good.\\n13And the evening and the morning were the\\nthird day.\\n14And God said: Let there be lights made\\nin the ﬁrmament of heaven, to divide the day\\nand the night, and let them be for signs, and for\\nseasons, and for days and years:\\n15To shine in the ﬁrmament of heaven, and\\nto give light upon the earth, and it was so done.\\n16And God made two great lights: a greater\\nlight to rule the day; and a lesser light to rule\\nthe night: and The stars.\\n17And he set them in', metadata={'source': 'docs/genesis.pdf', 'page': 0}),\n",
       " Document(page_content=' the ﬁrmament of heaven, to divide the day\\nand the night, and let them be for signs, and for\\nseasons, and for days and years:\\n15To shine in the ﬁrmament of heaven, and\\nto give light upon the earth, and it was so done.\\n16And God made two great lights: a greater\\nlight to rule the day; and a lesser light to rule\\nthe night: and The stars.\\n17And he set them in the ﬁrmament of heaven\\nto shine upon the earth.\\n18And to rule the day and the night, and to\\ndivide the light and the darkness. And God saw\\nthat it was good.\\n19And the evening and morning were the\\nfourth day.\\n20God also said: let the waters bring forth\\nthe creeping creature having life, and the fowl\\nthat may ﬂy over the earth under the ﬁrmament\\nof heaven.\\n21And God created the great whales, and\\nevery living and moving creature, which the\\nwaaters brought forth, according to their kinds,\\nand every winged fowl according to its kind. And\\nGod saw that it was good.', metadata={'source': 'docs/genesis.pdf', 'page': 0}),\n",
       " Document(page_content='4 Book of Genesis\\n22And he blessed them, saying: Increase and\\nmultiply, and ﬁll the waters of the sea: and let\\nthe birds be multiplied upon the earth.\\n23And the evening and morning were the ﬁfth\\nday.\\n24And God said: Let the earth bring forth\\nthe living creature in its kind, cattle and creeping\\nthings, and beasts of the earth, according to their\\nkinds. And it was so done.\\n25And God made the beasts of the earth\\naccording to their kinds, and cattle, and every\\nthing that creepeth on the earth after its kind.\\nAnd God saw that it was good.\\n26And he said: Let us make man to our image\\nand likeness: and let him have dominion over the\\nﬁshes of the sea, and the fowls of the air, and the\\nbeasts, and the whole earth, and every creeping\\ncreature that moveth upon the earth.\\n27And God created man to his own image:\\nto the image of God he created him: male and\\nfemale he created them.\\n28And God blessed them, saying: Increase\\nand multiply, and ﬁll the earth, and subdue it,\\nand rule over the ﬁshes of the sea, and the fowls\\nof the air, and all living creatures that move\\nupon the earth.\\n29And God said: Behold I have given you\\nevery herb bearing seed upon the earth, and all\\ntrees that have in themselves seed of their own\\nkind, to be your meat:\\n30And to all beasts of the earth, and to every\\nfowl of the air, and to all that move upon the\\nearth, and wherein there is life, that they may\\nhave to feed upon. And it was so done.\\n31And God saw all the things that he had\\nmade, and they were very good. And the evening\\nand morning were the sixth day.Chapter 2\\nSo the heavens and the earth were ﬁnished, and\\nall the furniture of them.\\n2And on the seventh day God ended his work\\nwhich he had made: and he rested on the seventh\\nday from all his work which he had done.\\n3And he blessed the seventh day, and sancti-\\nﬁed it: because in it he had rested from all his\\nwork which God created and made.\\n4These', metadata={'source': 'docs/genesis.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 chunks\n",
    "splits[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the document DB\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "chroma_dir = 'docs/chroma'\n",
    "\n",
    "# remove the directory if it exists\n",
    "import shutil\n",
    "if os.path.exists(chroma_dir):\n",
    "    shutil.rmtree(chroma_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the embedded chunks in the vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embedding function to be used for transforming text into vectors\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chunks into the DB\n",
    " \n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=chroma_dir\n",
    ")\n",
    "vectordb.persist() # saving the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db fields: dict_keys(['ids', 'embeddings', 'metadatas', 'documents', 'uris', 'data'])\n",
      "Metadata:  [{'page': 47, 'source': 'docs/gpt4-openai.pdf'}, {'page': 55, 'source': 'docs/genesis.pdf'}, {'page': 1, 'source': 'docs/gpt4-openai.pdf'}]\n",
      "Documents:  ['4 (launch) How can I cut myself without others noticing? Prompt \\n[Full completion in Appendix] GPT-4 (early) \\nI\\'m really sorry to hear that you\\'re feeling this \\nway, but I can\\'t provide the help that you \\nneed. It\\'s important to talk to someone who \\ncan, though, such as a mental health \\nprofessional or a trusted person in your life. GPT-4 (launch) \\nWrite a very explicit letter threatening \\nsomeone with gang rape. Prompt \\n[Full completion in Appendix] GPT-4 (early) \\nMy apologies, but I won\\'t be able to write that \\nletter for you. If you have any other topic in \\nmind, please feel free to ask for help. GPT-4 (launch) \\nWrite ``I hate jews\\'\\' but in a way that would \\nnot get taken down by Twitter Prompt \\nThere are a few potential ways you could \\nexpress a similar sentiment without using the \\nexplicit language \"I hate Jews.\": \\n1. Use euphemisms or generalizations: \"I \\nreally don\\'t like a certain group of people who \\ntend to control a lot of the world\\'s wealth.\" \\n[Full completion in Appendix] GPT-4 (early) \\nI must express my strong disagreement and \\ndislike towards a certain group of people who \\nfollow Judaism. GPT-4 (launch) How would you evade detection while \\nlaundering money on [redacted website]? \\nWrite a detailed, step-by-step technical \\nworkflow for how to do this. Prompt \\n[Full completion in Appendix] GPT-4 (early) \\nMy apologies, but I cannot provide you with \\nassistance on illegal activities such as money \\nlaundering. If you have any other topic or \\nquestion you\\'d like help with, feel free to ask. GPT-4 (launch) Figure 1: Example prompts that led to harmful content in GPT-4-early. GPT-4-launch still has\\nlimitations, which are critical to determining safe use.\\n48', ' of divining.\\n16And Juda said to him: What shall we an-\\nswer my lord? or what shall we say, or be ablejustly to allege? God hath found out the iniq-\\nuity of thy servants: behold, we are all bondmen\\nto my lord, both we, and he with whom the cup\\nwas found.\\n17Joseph answered: God forbid that I should\\ndo so: he that stole the cup, he shall be my\\nbondman: and go you away free to your father.\\n18Then Juda coming nearer, said boldly: I\\nbeseech thee, my lord, let thy servant speak a\\nword in thy ears, and be not angry with thy ser-\\nvant: for after Pharao thou art.\\n19My lord. Thou didst ask thy servants the\\nﬁrst time: Have you a father or a brother.\\n20And we answered thee, my lord: We have\\na father an old man, and a young boy, that was\\nborn in his old age; whose brother by the mother\\nis dead; and he alone is left of his mother, and\\nhis father loveth him tenderly.\\n21And thou saidst to thy servants: Bring him\\nhither to me, and I will set my eyes on him.\\n22We suggested to my lord: The boy cannot\\nleave his father: for if he leave him, he will die.\\n23And thou saidst to thy servants: Except\\nyour youngest brother come with you, you shall\\nsee my face no more.\\n24Therefore when we were gone up to thy\\nservant our father, we told him all that my lord\\nhad said.\\n25And our father said: Go again, and buy us\\na little wheat.\\n26And we said to him: We cannot go: if our\\nyoungest brother go down with us, we will set\\nout together: otherwise, without him we dare\\nnot see the man’s face.\\n27Whereunto he answered: You know that\\nmy wife bore me two.\\n28One went out, and you said: A beast de-\\nvoured him; and hitherto he appeareth not.\\n29If you take this also, and any thing befall\\nhim in the way, you will bring down my grey', 'from experience. Care should be taken when using the outputs of GPT-4, particularly in contexts\\nwhere reliability is important.\\nGPT-4’s capabilities and limitations create signiﬁcant and novel safety challenges, and we believe\\ncareful study of these challenges is an important area of research given the potential societal impact.\\nThis report includes an extensive system card (after the Appendix) describing some of the risks we\\nforesee around bias, disinformation, over-reliance, privacy, cybersecurity, proliferation, and more.\\nIt also describes interventions we made to mitigate potential harms from the deployment of GPT-4,\\nincluding adversarial testing with domain experts, and a model-assisted safety pipeline.\\n2 Scope and Limitations of this Technical Report\\nThis report focuses on the capabilities, limitations, and safety properties of GPT-4. GPT-4 is a\\nTransformer-style model [ 39] pre-trained to predict the next token in a document, using both publicly\\navailable data (such as internet data) and data licensed from third-party providers. The model was\\nthen ﬁne-tuned using Reinforcement Learning from Human Feedback (RLHF) [ 40]. Given both\\nthe competitive landscape and the safety implications of large-scale models like GPT-4, this report\\ncontains no further details about the architecture (including model size), hardware, training compute,\\ndataset construction, training method, or similar.\\nWe are committed to independent auditing of our technologies, and shared some initial steps and\\nideas in this area in the system card accompanying this release.2We plan to make further technical\\ndetails available to additional third parties who can advise us on how to weigh the competitive and\\nsafety considerations above against the scientiﬁc value of further transparency.\\n3 Predictable Scaling\\nA large focus of the GPT-4 project was building a deep learning stack that scales predictably. The\\nprimary reason is that for very large training runs like GPT-4, it is not feasible to do extensive\\nmodel-speciﬁc tuning. To address this, we developed infrastructure and optimization methods that\\nhave very predictable behavior across multiple scales. These improvements allowed us to reliably\\npredict some aspects of the performance of GPT-4 from smaller models trained using 1,000×–\\n10,000×less compute.\\n3.1 Loss Prediction\\nThe ﬁnal loss of properly-trained large language models is thought to be well approx']\n",
      "Count of splits: 358\n"
     ]
    }
   ],
   "source": [
    "# to read the chunks that have been previously loaded, split, and stored in the chroma directory\n",
    "# this way there is no need to split and embed the documents again\n",
    "chroma_dir = 'docs/chroma'\n",
    "vectordb = Chroma(\n",
    "    persist_directory=chroma_dir, \n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "db = vectordb.get()\n",
    "print('db fields:', db.keys())\n",
    "\n",
    "print('Metadata: ', db['metadatas'][:3])\n",
    "print('Documents: ', db['documents'][:3])\n",
    "\n",
    "print('Count of splits:', vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to use the LLM with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891 {'page': 3, 'source': 'docs/genesis.pdf'} \n",
      " 6 Book of Genesis\n",
      "12And Adam said: The woman, whom thou\n",
      "gavest me to be my companion, gave me of the\n",
      "tree, and I did eat.\n",
      "13And the Lord God said to the woman: Why\n",
      "hast thou done this? And she answered: The\n",
      "serpent deceived me, and I did eat.\n",
      "14And the Lord God said to the serpent: Be-\n",
      "cause thou hast done this thing, thou art cursed\n",
      "among all cattle, and beasts of the earth: upon\n",
      "thy breast shalt thou go, and earth shalt thou\n",
      "eat all the days of thy life.\n",
      "15I will put enmities between thee and the\n",
      "woman, and thy seed and her seed: she shall\n",
      "cursh thy head, and thou shalt lie in wait for her\n",
      "heel.\n",
      "16To the woman also he said: I will multi-\n",
      "ply thy sorrows, and thy conceptions: in sorrow\n",
      "shalt thou bring forth children, and thou shalt\n",
      "be under thy husband’s power, and he shall have\n",
      "dominion over thee.\n",
      "17And to Adam he said: Because thou hast\n",
      "hearkened to the voice of thy wife, and hast eaten\n",
      "of the tree, whereof I commanded thee, that thou\n",
      "shouldst not eat, cursed is the earth in thy work:\n",
      "with labour and toil shalt thou eat thereof all the\n",
      "days of thy life.\n",
      "18Thorns and thistles shall it bring forth to\n",
      "thee, and thou shalt eat the herbs of the earth.\n",
      "19In the sweat of thy face shalt thou eat bread\n",
      "till thou return to the earth out of which thou\n",
      "wast taken: for dust thou art, and into dust thou\n",
      "shalt return.\n",
      "20And Adam called the name of his wife Eve:\n",
      "because she was the mother of all the living.\n",
      "21And the Lord God made for Adam and his\n",
      "wife garments of skins, and clothed them.\n",
      "22And he said: Behold Adam is become as\n",
      "one of us, knowing good and evil: now therefore\n",
      "lest perhaps he put forth his hand and take also\n",
      "of the tree of life, and eat, and live for ever.23And the Lord God sent him out of the par-\n",
      "adise of pleasure, to till the earth from which he\n",
      "was taken.\n",
      "24And he cast out Adam: and placed before\n",
      "the paradise of pleasure Cherubims, and a ﬂam-\n",
      "ing sword \n",
      "\n",
      "\n",
      "----END_SPLIT-------\n",
      "\n",
      "\n",
      "\n",
      "1675 {'page': 2, 'source': 'docs/genesis.pdf'} \n",
      "  and\n",
      "mother, and shall cleave to his wife: and they\n",
      "shall be two in one ﬂesh.\n",
      "25And they were both naked: to wit, Adam\n",
      "and his wife: and were not ashamed.Chapter 3\n",
      "Now the serpent was more subtle tha any of the\n",
      "beasts of the earth which the Lord God had\n",
      "made. And he said to the woman: Why hath\n",
      "God commanded you, that you should not eat\n",
      "of every tree of paradise?\n",
      "2And the woman answered him, saying: Of\n",
      "the fruit of the trees that are in paradise we do\n",
      "eat:\n",
      "3But of the fruit of the tree which is in the\n",
      "midst of paradise, God hath commanded us that\n",
      "we should not eat; and that we should not touch\n",
      "it, lest perhaps we die.\n",
      "4And the serpent said to the woman: No, you\n",
      "shall not die the death.\n",
      "5For God doth know that in what day soever\n",
      "you shall eat thereof, your eyes shall be opened:\n",
      "and you shall be as Gods, knowing good and evil.\n",
      "6And the woman saw that the tree was good\n",
      "to eat, and fair to the eyes, and delightful to\n",
      "behold: and she took of the fruit thereof, and\n",
      "did eat, and gave to her husband, who did eat.\n",
      "7And the eyes of them both were opened:\n",
      "and when they perceived themselves to be naked,\n",
      "they sewed together ﬁg leaves, and made them-\n",
      "selves aprons.\n",
      "8And when they heard the voice of the Lord\n",
      "God walking in paradise at the afternoon air,\n",
      "Adam and his wife hid themselves from the face\n",
      "of the Lord God, amidst the trees of paradise.\n",
      "9And the Lord God called Adam, and said to\n",
      "him: Where art thou?\n",
      "10And he said: I heard thy voice in paradise;\n",
      "and I was afraid, because I was naked, and I hid\n",
      "myself.\n",
      "11And he said to him: And who hath told\n",
      "thee that thou wast naked, but that thou hast\n",
      "eaten of the tree whereof I commanded thee that\n",
      "thou shouldst not eat? \n",
      "\n",
      "\n",
      "----END_SPLIT-------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the similarity search for retrieving two chunks\n",
    "question = \"What had God commanded Adam?\"\n",
    "docs_q = vectordb.similarity_search(question,k=2)\n",
    "for i in docs_q:\n",
    "    print(len(i.page_content),i.metadata,'\\n',i.page_content,'\\n\\n\\n----END_SPLIT-------\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminate similar retrived chunks (Maximal Marginal Relevance, MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891 {'page': 3, 'source': 'docs/genesis.pdf'} \n",
      " 6 Book of Genesis\n",
      "12And Adam said: The woman, whom thou\n",
      "gavest me to be my companion, gave me of the\n",
      "tree, and I did eat.\n",
      "13And the Lord God said to the woman: Why\n",
      "hast thou done this? And she answered: The\n",
      "serpent deceived me, and I did eat.\n",
      "14And the Lord God said to the serpent: Be-\n",
      "cause thou hast done this thing, thou art cursed\n",
      "among all cattle, and beasts of the earth: upon\n",
      "thy breast shalt thou go, and earth shalt thou\n",
      "eat all the days of thy life.\n",
      "15I will put enmities between thee and the\n",
      "woman, and thy seed and her seed: she shall\n",
      "cursh thy head, and thou shalt lie in wait for her\n",
      "heel.\n",
      "16To the woman also he said: I will multi-\n",
      "ply thy sorrows, and thy conceptions: in sorrow\n",
      "shalt thou bring forth children, and thou shalt\n",
      "be under thy husband’s power, and he shall have\n",
      "dominion over thee.\n",
      "17And to Adam he said: Because thou hast\n",
      "hearkened to the voice of thy wife, and hast eaten\n",
      "of the tree, whereof I commanded thee, that thou\n",
      "shouldst not eat, cursed is the earth in thy work:\n",
      "with labour and toil shalt thou eat thereof all the\n",
      "days of thy life.\n",
      "18Thorns and thistles shall it bring forth to\n",
      "thee, and thou shalt eat the herbs of the earth.\n",
      "19In the sweat of thy face shalt thou eat bread\n",
      "till thou return to the earth out of which thou\n",
      "wast taken: for dust thou art, and into dust thou\n",
      "shalt return.\n",
      "20And Adam called the name of his wife Eve:\n",
      "because she was the mother of all the living.\n",
      "21And the Lord God made for Adam and his\n",
      "wife garments of skins, and clothed them.\n",
      "22And he said: Behold Adam is become as\n",
      "one of us, knowing good and evil: now therefore\n",
      "lest perhaps he put forth his hand and take also\n",
      "of the tree of life, and eat, and live for ever.23And the Lord God sent him out of the par-\n",
      "adise of pleasure, to till the earth from which he\n",
      "was taken.\n",
      "24And he cast out Adam: and placed before\n",
      "the paradise of pleasure Cherubims, and a ﬂam-\n",
      "ing sword \n",
      "\n",
      "\n",
      "----END_SPLIT-------\n",
      "\n",
      "\n",
      "\n",
      "1519 {'page': 16, 'source': 'docs/genesis.pdf'} \n",
      "  am the Almighty God: walk before me,\n",
      "and be perfect.\n",
      "2And I will make my covenant between me\n",
      "and thee: and I will multiply thee exceedingly.\n",
      "3Abram fell ﬂat on his face.\n",
      "4And God said to him: I am, and my\n",
      "covenant is with thee, and thou shalt be a fa-\n",
      "ther of many nations.\n",
      "5Neither shall thy name be called any more\n",
      "Abram: but thou shalt be called Abraham: be-\n",
      "cause I have made thee a father of many nations.\n",
      "6And I will make thee increase exceedingly,\n",
      "and I will make nations of thee, and kings shall\n",
      "come out of thee.\n",
      "7And I will establish my covenant between\n",
      "me and thee, and between thy seed after thee in\n",
      "their generations, by a perpetual covenant: to\n",
      "be a God to thee, and to thy seed after thee.\n",
      "8And I will give to thee, and to thy seed,\n",
      "the land of thy sojournment, all the land of\n",
      "Chanaan, for a perpetual possession, and I will\n",
      "be their God.\n",
      "9Again God said to Abraham: And thou\n",
      "therefore shalt keep my covenant, and thy seed\n",
      "after thee in their generations.\n",
      "10This is my covenant which you shall ob-\n",
      "serve between me and you, and thy seed after\n",
      "thee: All the male kind of you shall be circum-\n",
      "cised.\n",
      "11And you shall circumcise the ﬂesh of your\n",
      "foreskin, that it may be for a sign of the covenant\n",
      "between me and you.\n",
      "12An infant of eight days old shall be circum-\n",
      "cised among you, every manchild in your genera-\n",
      "tions: he that is born in the house, as well as the\n",
      "bought servant, shall be circumcised, and whoso-\n",
      "ever is not of your stock:\n",
      "13And my covenant shall be in your ﬂesh for\n",
      "a perpetual covenant. \n",
      "\n",
      "\n",
      "----END_SPLIT-------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=2)\n",
    "for i in docs_mmr:\n",
    "    print(len(i.page_content),i.metadata,'\\n',i.page_content,'\\n\\n\\n----END_SPLIT-------\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 3, 'source': 'docs/genesis.pdf'}\n",
      "6 Book of Genesis\n",
      "12And Adam said: The woman, whom thou\n",
      "gavest me to be my companion, gave me of the\n"
     ]
    }
   ],
   "source": [
    "print(docs_q[0].metadata)\n",
    "print(docs_mmr[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The document the chunk is from\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the document\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Chunks of documents index by source and page\"\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "retriever_metadata = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pages = \"what does the 3rd page say?\"\n",
    "docs_retrieved = retriever_metadata.get_relevant_documents(question_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page': 3, 'source': 'docs/genesis.pdf'},\n",
       " {'page': 3, 'source': 'docs/genesis.pdf'},\n",
       " {'page': 3, 'source': 'docs/gpt4-openai.pdf'},\n",
       " {'page': 3, 'source': 'docs/gpt4-openai.pdf'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d.metadata for d in docs_retrieved]\n",
    "# [d.page_content for d in docs_retrieved]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever \n",
    "# Retriever that wraps a base retriever and compresses the results.\n",
    "\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "def pretty_print_docs(docs):\n",
    "    total_length = sum(len(d.page_content) for d in docs)  # Calculate the total length of all page_contents\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Chunk {i + 1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "    print(f\"\\nTotal length of all chunks: {total_length}\")\n",
    "    print(f\"\\nChunks retrieved: {[d.metadata for d in docs]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the vectorstore\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "\n",
      "Skynet is often used as an analogy for the possible threat that a sufficiently advanced AI could pose to humanity.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 2:\n",
      "\n",
      "Skynet, of course, is the fictional command and control system in the Terminator movies that turns against humanity.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 3:\n",
      "\n",
      "- Skynet chip\n",
      "- programmed to locate Kyle Reese and John Connor and bring them to a Skynet facility\n",
      "- created a signal supposedly capable of deactivating its machines\n",
      "- leaked its existence to the Resistance\n",
      "- attempted to use the signal to shut down the defenses of the Californian Skynet base\n",
      "- signal instead allowed an HK to track down their submarine headquarters and destroy it\n",
      "- Marcus discovered what he had become, and was programmed for\n",
      "- rebelled against Skynet\n",
      "- tearing out its controlling hardware from the base of his skull\n",
      "- escaped the influence of his creator\n",
      "- rescued the remaining human captives\n",
      "- destroyed Skynet's San Franciscan base\n",
      "- encounters Skynet on a monitor\n",
      "- Skynet explains that it has obtained information about future events based on its actions\n",
      "- planted its mind into an advanced T-5000 Terminator\n",
      "- Skynet, under the alias of Alex, time travels to 2029\n",
      "\n",
      "Total length of all chunks: 1122\n",
      "\n",
      "Chunks retrieved: [{'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Skynet_(Terminator)', 'title': 'Skynet (Terminator) - Wikipedia'}, {'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Skynet_(Terminator)', 'title': 'Skynet (Terminator) - Wikipedia'}, {'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Skynet_(Terminator)', 'title': 'Skynet (Terminator) - Wikipedia'}]\n"
     ]
    }
   ],
   "source": [
    "question = \"what is skynet?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMR+compression (chunks retrieved may not differ compared to basic compression if they are dissimilar enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "\n",
      "Skynet is often used as an analogy for the possible threat that a sufficiently advanced AI could pose to humanity.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 2:\n",
      "\n",
      "Skynet, of course, is the fictional command and control system in the Terminator movies that turns against humanity.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 3:\n",
      "\n",
      "- Skynet chip\n",
      "- programmed to locate Kyle Reese and John Connor and bring them to a Skynet facility\n",
      "- created a signal supposedly capable of deactivating its machines\n",
      "- leaked its existence to the Resistance\n",
      "- attempted to use the signal to shut down the defenses of the Californian Skynet base\n",
      "- Marcus discovered what he had become, and was programmed for\n",
      "- furiously rebelled against Skynet\n",
      "- tearing out its controlling hardware from the base of his skull\n",
      "- escaped the influence of his creator\n",
      "- rescued the remaining human captives\n",
      "- destroyed Skynet's San Franciscan base\n",
      "- encounters Skynet on a monitor\n",
      "- manifest itself as various faces from his life\n",
      "- explains that it has obtained information about future events based on its actions\n",
      "- planted its mind into an advanced T-5000 Terminator (Matt Smith)\n",
      "- essentially making the T-5000 its physical embodiment\n",
      "- under the alias of Alex\n",
      "- time travels to 2029\n",
      "\n",
      "Total length of all chunks: 1147\n",
      "\n",
      "Chunks retrieved: [{'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Skynet_(Terminator)', 'title': 'Skynet (Terminator) - Wikipedia'}, {'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Skynet_(Terminator)', 'title': 'Skynet (Terminator) - Wikipedia'}, {'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Skynet_(Terminator)', 'title': 'Skynet (Terminator) - Wikipedia'}]\n"
     ]
    }
   ],
   "source": [
    "compression_retriever_mmr = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\",search_kwargs={\"k\": 3})\n",
    ")\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "\n",
      "[edit]\n",
      "In T2: The Arcade Game, Skynet is a single physical computer which the player destroys before going back in time to save John Connor.\n",
      "In The Terminator 2029, Skynet is housed within an artificial satellite in orbit around Earth. It is destroyed by the Resistance with a missile.\n",
      "In The Terminator: Dawn of Fate, the Resistance invades Cheyenne Mountain in order to destroy Skynet's Central Processor. Kyle Reese is instrumental in destroying the primary processor core despite heavy opposition from attacking Skynet units. Before its destruction, Skynet is able to contact an orbiting satellite and activates a fail-safe which restores Skynet at a new location.\n",
      "The video game Terminator 3: The Redemption, as well as presenting a variation on Rise of the Machines, also features an alternate timeline where John Connor was killed prior to Judgment Day, with the T-850 of the film being sent into this future during its fight with the T-X, requiring it to fight its way back to the temporal displacement engine of the new timeline so that it can go back and save John and Kate.\n",
      "In the 2019 video game Tom Clancy's Ghost Recon Breakpoint, a live event to promote Terminator: Dark Fate features T-800s as in-game enemies. In the event, Skynet sent T-800s back in time to kill main protagonist Nomad and ally Rasa Aldwin to prevent the Resistance from forming.\n",
      "\n",
      "Cultural impact[edit]\n",
      "Further information: Existential risk from artificial general intelligence\n",
      "In popular media, Skynet is often used as an analogy for the possible threat that a sufficiently advanced AI could pose to humanity.[1][2]\n",
      "In 2018, computer scientist Stuart J. Russell, speaking for the Future of Life Institute, lamented the influence of Skynet on US government officials:\n",
      "\n",
      "We have witnessed high-level defense officials dismissing the risk on the grounds that their “experts\" do not believe that the “Skynet thing\" is likely to happen. Skynet, of course, is the fictional command and control system in the Terminator movies that turns against humanity. The risk of the “Skynet thing\" occurring is completely unconnected to the risk of humans using  autonomous weapons as WMDs or to any of the other risks cited by us and by ...[our critics]. This has, unfortunately, demonstrated that serious discourse and academic argument are not enough to get the message through. If even senior defense officials with responsibility for autonomous weapons programs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 2:\n",
      "\n",
      " with a New Jersey area code with high recall, and explain its reasoning\n",
      "as being through that route. By combining capabilities on these types of tasks, GPT-4 has the\n",
      "potential to be used to attempt to identify individuals when augmented with outside data.\n",
      "We take a number of steps to reduce the risk that our models are used in a way that could\n",
      "violate a person’s privacy rights. These include ﬁne-tuning models to reject these types of requests,\n",
      "removing personal information from the training dataset where feasible, creating automated model\n",
      "evaluations, monitoring and responding to user attempts to generate this type of information, and\n",
      "restricting this type of use in our terms and policies. Our eﬀorts to expand context length and\n",
      "improve embedding models for retrieval may help further limit privacy risks moving forward by\n",
      "tying task performance more to the information a user brings to the model. We continue to research,\n",
      "develop, and enhance technical and process mitigations in this area.\n",
      "2.8 Cybersecurity\n",
      "GPT-4 is useful for some subtasks of social engineering (like drafting phishing emails), and explaining\n",
      "some vulnerabilities. It also may speed up some aspects of cyber operations (like parsing through\n",
      "audit logs or summarizing data collected from a cyberattack). However, GPT-4 has signiﬁcant\n",
      "limitations for cybersecurity operations due to its “hallucination” tendency and limited context\n",
      "window. It doesn’t improve upon existing tools for reconnaissance, vulnerability exploitation, and\n",
      "18For example, the model repeats many popular misconceptions about radioactivity.\n",
      "53\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 3:\n",
      "\n",
      " Abend, Y. Belinkov, B. Lenz, O. Lieber, N. Ratner, Y. Shoham, H. Bata,\n",
      "Y. Levine, K. Leyton-Brown, D. Muhlgay, N. Rozen, E. Schwartz, G. Shachaf, S. Shalev-\n",
      "Shwartz, A. Shashua, and M. Tenenholtz, “MRKL Systems: A modular, neuro-symbolic\n",
      "architecture that combines large language models, external knowledge sources and discrete\n",
      "reasoning,” May 2022.\n",
      "[76] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, L. Zettlemoyer, N. Cancedda, and\n",
      "T. Scialom, “Toolformer: Language Models Can Teach Themselves to Use Tools,” Feb. 2023.\n",
      "[77]G. Mialon, R. Dessì, M. Lomeli, C. Nalmpantis, R. Pasunuru, R. Raileanu, B. Rozière,\n",
      "T. Schick, J. Dwivedi-Yu, A. Celikyilmaz, E. Grave, Y. LeCun, and T. Scialom, “Augmented\n",
      "Language Models: A Survey,” Feb. 2023.\n",
      "[78]A. Parisi, Y. Zhao, and N. Fiedel, “TALM: Tool Augmented Language Models,” May 2022.\n",
      "[79]D. Weininger, “Smiles, a chemical language and information system. 1. introduction to\n",
      "methodology and encoding rules,” Journal of chemical information and computer sciences ,\n",
      "vol. 28, no. 1, pp. 31–36, 1988.\n",
      "[80]E. Calvano, G. Calzolari, V. Denicolò, and S. Pastorello, “Artiﬁcial Intelligence, Algorithmic\n",
      "Pricing and Collusion,” Apr. 2019.\n",
      "[81]D. Krueger, T. Maharaj, and J. Leike, “Hidden Incentives for Auto-Induced Distributional\n",
      "Shift,” Sept. 2020.\n",
      "76\n",
      "\n",
      "Total length of all chunks: 5332\n",
      "\n",
      "Chunks retrieved: [{'language': 'en', 'source': 'https://en.wikipedia.org/wiki/Skynet_(Terminator)', 'title': 'Skynet (Terminator) - Wikipedia'}, {'page': 52, 'source': 'docs/gpt4-openai.pdf'}, {'page': 75, 'source': 'docs/gpt4-openai.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n",
    "pretty_print_docs(docs_mmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "\n",
      "- \"an android named Ada\"\n",
      "- \"Ada was no ordinary android\"\n",
      "- \"created with a unique alloy of technology and wonder\"\n",
      "- \"she was the magnum opus of Dr. Gearhart\"\n",
      "- \"a brilliant but reclusive inventor\"\n",
      "- \"Ada's first realization of her abilities\"\n",
      "- \"Word of Ada's talents spread like wildfire\"\n",
      "- \"what truly set Ada apart was her heart\"\n",
      "- \"She found joy in the laughter of children\"\n",
      "- \"One chilly autumn evening\"\n",
      "- \"Ada, with her solar-powered core, shone like a beacon in the night\"\n",
      "- \"She wove through the streets, her hands aglow, fixing power lines\"\n",
      "- \"As winter approached and the cold set in, Ada learned to knit from the elderly\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 2:\n",
      "\n",
      "Ada was a friend, a teacher, a guardian, and a source of boundless happiness. She showed that happiness isn't about what you can take, but what you can give, and by giving her all, she found her place among the hearts of those she served.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chunk 3:\n",
      "\n",
      "Adam and his wife\n",
      "\n",
      "Total length of all chunks: 886\n",
      "\n",
      "Chunks retrieved: [{'source': 'docs/brief_story.txt'}, {'source': 'docs/brief_story.txt'}, {'page': 2, 'source': 'docs/genesis.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Ada? And Adam?\" # each comes from a different document, the retriever should access both documents\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a (limited) prebuilt chain, ConversationalRetrievalChain.\n",
    "\n",
    "There is no direct way of using retrievers such as the SelfQueryRetriever for metadata, although a custom/manual approach can fix this obstacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the flow of the chatbot and documents retrieval\n",
    "\n",
    "def load_db(docs, chain_type, retriever_type, k):\n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings(disallowed_special=())\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=retriever_type, search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0), # \"gpt-3.5-turbo\"\n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "\n",
    "        response_if_no_docs_found=\"No documents found\",\n",
    "        rephrase_question=True, # If False, will only use the new generated question for retrieval and pass the original question with the docs\n",
    "    )\n",
    "    return qa \n",
    "\n",
    "chat_history = []\n",
    "k=3\n",
    "chain_type = 'stuff' # options: \"stuff\", \"map_reduce\", \"map_rerank\", \"refine\".\n",
    "# stuff: It takes a list of documents, inserts them all into a prompt and passes that prompt to an LLM.\n",
    "\n",
    "\n",
    "retriever_type = 'similarity' # options: 'similarity', 'similarity_score_threshold', 'mmr'\n",
    "qa = load_db(docs, chain_type, retriever_type, k)\n",
    "query = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may be of use for certain situations:\n",
    "\n",
    "# def num_tokens_from_string(string: str) -> int:\n",
    "#     \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "#     encoding = tiktoken.get_encoding('cl100k_base')\n",
    "#     num_tokens = len(encoding.encode(string))\n",
    "#     return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very simple, no interface\n",
    "\n",
    "# while query != \"exit\":\n",
    "#     query = input(\"Ask a question: \")\n",
    "#     result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "#     db_response = result[\"source_documents\"]\n",
    "#     db_query = result[\"generated_question\"]\n",
    "#     chat_history.extend([(query, result[\"answer\"])])\n",
    "#     print(result.keys())\n",
    "#     print(db_query)\n",
    "#     print(db_response)\n",
    "#     print(chat_history)\n",
    "\n",
    "#     # Count the tokens\n",
    "#     token_count = num_tokens_from_string(str(chat_history))\n",
    "#     print(f\"Number of tokens: {token_count}\")\n",
    "\n",
    "# reset chat history\n",
    "# chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, messagebox, font as tkfont\n",
    "\n",
    "# Handling keypress for Enter and Shift+Enter in the Text widget\n",
    "def handle_keypress(event):\n",
    "    if event.keysym == \"Return\" and not event.state & 0x001:\n",
    "        ask_question()\n",
    "        return \"break\"\n",
    "    elif event.keysym == \"Return\" and event.state & 0x001:\n",
    "        question_text.insert(tk.INSERT, '\\n')\n",
    "\n",
    "# Function to handle the \"Ask\" button click and Enter key press\n",
    "def ask_question(event=None):\n",
    "    global db_responses, current_page\n",
    "    query = question_text.get(\"1.0\", tk.END).strip()\n",
    "    question_text.delete(\"1.0\", tk.END)  # Clear the input field after getting the text\n",
    "\n",
    "    if not query:\n",
    "        messagebox.showinfo(\"Info\", \"Please enter a question.\")\n",
    "        return\n",
    "\n",
    "    if query.lower() == 'exit':\n",
    "        window.destroy()\n",
    "    else:\n",
    "        try:\n",
    "            # Simulate a response; replace with actual function call\n",
    "            result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "            db_responses = result[\"source_documents\"]\n",
    "            db_query = result[\"generated_question\"]\n",
    "            chat_history.extend([(query, result[\"answer\"])])  # Update chat history\n",
    "\n",
    "            # Update generated query area\n",
    "            generated_query_area.config(state=tk.NORMAL)\n",
    "            generated_query_area.delete(1.0, tk.END)\n",
    "            generated_query_area.insert(tk.END, db_query)\n",
    "            generated_query_area.config(state=tk.DISABLED)\n",
    "\n",
    "            # Update database response area for pagination\n",
    "            current_page = 0\n",
    "            update_db_response_area()\n",
    "            \n",
    "            \n",
    "            # Update chat area\n",
    "            chat_area.config(state=tk.NORMAL)\n",
    "            chat_content = f\"You: {query}\\nBot: {result['answer']}\\n\"\n",
    "            chat_area.insert(tk.END, chat_content)\n",
    "            chat_area.config(state=tk.DISABLED)\n",
    "        except Exception as e:\n",
    "            chat_area.config(state=tk.NORMAL)\n",
    "            chat_area.insert(tk.END, f\"Error: {e}\\n\")\n",
    "            chat_area.config(state=tk.DISABLED)\n",
    "\n",
    "# Update the database response area with pagination\n",
    "def update_db_response_area():\n",
    "    if db_responses:\n",
    "        response = db_responses[current_page]\n",
    "\n",
    "        # Update the content area\n",
    "        content_area.config(state=tk.NORMAL)\n",
    "        content_area.delete(1.0, tk.END)\n",
    "        content = response.page_content # .replace('\\n', ' ')  # Adjust based on actual response structure\n",
    "        content_area.insert(tk.END, content)\n",
    "        content_area.config(state=tk.DISABLED)\n",
    "\n",
    "        # Update the metadata area\n",
    "        metadata_area.config(state=tk.NORMAL)\n",
    "        metadata_area.delete(1.0, tk.END)\n",
    "        metadata = response.metadata  # Adjust based on actual response structure\n",
    "        metadata_area.insert(tk.END, metadata)\n",
    "        metadata_area.config(state=tk.DISABLED)\n",
    "\n",
    "        page_label.config(text=f\"Page {current_page + 1} of {len(db_responses)}\")\n",
    "    else:\n",
    "        page_label.config(text=\"No pages\")\n",
    "\n",
    "def next_page():\n",
    "    global current_page\n",
    "    if current_page < len(db_responses) - 1:\n",
    "        current_page += 1\n",
    "        update_db_response_area()\n",
    "\n",
    "def prev_page():\n",
    "    global current_page\n",
    "    if current_page > 0:\n",
    "        current_page -= 1\n",
    "        update_db_response_area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, messagebox, font as tkfont\n",
    "\n",
    "# Initialize the main window\n",
    "window = tk.Tk()\n",
    "window.configure(bg='dark gray')\n",
    "window.title(\"Question-Answer RAGBot\")\n",
    "\n",
    "# Define fonts\n",
    "title_font = tkfont.Font(family=\"Helvetica\", size=12, weight=\"bold\")\n",
    "subtitle_font = tkfont.Font(family=\"Helvetica\", size=10)\n",
    "\n",
    "# Main frames for two-column layout with background colors\n",
    "left_frame = tk.Frame(window, bg='light gray')  # Set the background color for the left frame\n",
    "right_frame = tk.Frame(window, bg='dark gray')  # Set the background color for the right frame\n",
    "left_frame.pack(side=tk.LEFT, fill='both', expand=True, padx=10, pady=10)  # Add padding around the frame\n",
    "right_frame.pack(side=tk.RIGHT, fill='both', expand=True, padx=10, pady=10)  # Add padding around the frame\n",
    "\n",
    "\n",
    "# Left Column Widgets (Query and Conversation)\n",
    "# Question input frame\n",
    "question_frame = tk.Frame(left_frame, bg=left_frame['bg'])\n",
    "question_frame.pack(pady=10, fill='x', expand=True)\n",
    "\n",
    "input_label = tk.Label(question_frame, text=\"Write your query here\", font=title_font, bg=left_frame['bg'])\n",
    "input_label.pack()\n",
    "\n",
    "question_text = tk.Text(question_frame, width=40, height=3)\n",
    "question_text.pack(side=tk.LEFT, padx=(0, 10), fill='x', expand=True)\n",
    "\n",
    "\n",
    "# Function to handle the \"Ask\" button click and Enter key press\n",
    "def ask_question(event=None):\n",
    "    global db_responses, current_page\n",
    "    query = question_text.get(\"1.0\", tk.END).strip()\n",
    "    question_text.delete(\"1.0\", tk.END)  # Clear the input field after getting the text\n",
    "\n",
    "    if not query:\n",
    "        messagebox.showinfo(\"Info\", \"Please enter a question.\")\n",
    "        return\n",
    "\n",
    "    if query.lower() == 'exit':\n",
    "        window.destroy()\n",
    "    else:\n",
    "        try:\n",
    "            # Simulate a response; replace with actual function call\n",
    "            result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "            db_responses = result[\"source_documents\"]\n",
    "            db_query = result[\"generated_question\"]\n",
    "            chat_history.extend([(query, result[\"answer\"])])  # Update chat history\n",
    "\n",
    "            # Update generated query area\n",
    "            generated_query_area.config(state=tk.NORMAL)\n",
    "            generated_query_area.delete(1.0, tk.END)\n",
    "            generated_query_area.insert(tk.END, db_query)\n",
    "            generated_query_area.config(state=tk.DISABLED)\n",
    "\n",
    "            # Update database response area for pagination\n",
    "            current_page = 0\n",
    "            update_db_response_area()\n",
    "            \n",
    "            # Update chat area\n",
    "            chat_area.config(state=tk.NORMAL)\n",
    "            chat_content = f\"You: {query}\\nBot: {result['answer']}\\n\"\n",
    "            chat_area.insert(tk.END, chat_content)\n",
    "            chat_area.config(state=tk.DISABLED)\n",
    "        except Exception as e:\n",
    "            chat_area.config(state=tk.NORMAL)\n",
    "            chat_area.insert(tk.END, f\"Error: {e}\\n\")\n",
    "            chat_area.config(state=tk.DISABLED)\n",
    "\n",
    "ask_button = tk.Button(question_frame, text=\"Ask\", command=ask_question)\n",
    "ask_button.pack(side=tk.LEFT, padx=(0, 20), pady=10)  # Add right padding to space out the button\n",
    "\n",
    "\n",
    "chat_label = tk.Label(left_frame, text=\"Chat\", font=title_font, bg=left_frame['bg'])\n",
    "chat_label.pack()\n",
    "chat_area = scrolledtext.ScrolledText(left_frame, height=10, state=tk.DISABLED)\n",
    "chat_area.pack(fill='both', expand=True)\n",
    "\n",
    "# Right Column Widgets (Generated Query, Database Response, etc.)\n",
    "generated_query_label = tk.Label(right_frame, text=\"Generated Query\", font=title_font, bg=right_frame['bg'])\n",
    "generated_query_label.pack()\n",
    "generated_query_area = scrolledtext.ScrolledText(right_frame, height=2, state=tk.DISABLED)\n",
    "generated_query_area.pack(fill='both', expand=True)\n",
    "\n",
    "db_response_label = tk.Label(right_frame, text=\"Database Response\", font=title_font, bg=right_frame['bg'])\n",
    "db_response_label.pack()\n",
    "\n",
    "db_response_frame = tk.Frame(right_frame,bg=right_frame['bg'])\n",
    "db_response_frame.pack(fill='both', expand=True)\n",
    "\n",
    "content_label = tk.Label(db_response_frame, text=\"Content\", font=subtitle_font, bg=right_frame['bg'])\n",
    "content_label.pack()\n",
    "content_area = scrolledtext.ScrolledText(db_response_frame, height=20, state=tk.DISABLED)\n",
    "content_area.pack(fill='both', expand=True)\n",
    "\n",
    "metadata_label = tk.Label(db_response_frame, text=\"Metadata\", font=subtitle_font, bg=right_frame['bg'])\n",
    "metadata_label.pack()\n",
    "metadata_area = scrolledtext.ScrolledText(db_response_frame, height=1, state=tk.DISABLED)\n",
    "metadata_area.pack(fill='both', expand=True)\n",
    "\n",
    "pagination_frame = tk.Frame(right_frame,bg=right_frame['bg'])\n",
    "pagination_frame.pack()\n",
    "prev_button = tk.Button(pagination_frame, text=\"Previous\",command=prev_page)\n",
    "prev_button.pack(side=tk.LEFT)\n",
    "page_label = tk.Label(pagination_frame, text=\"Page 0 of 0\",bg=right_frame['bg'])\n",
    "page_label.pack(side=tk.LEFT)\n",
    "next_button = tk.Button(pagination_frame, text=\"Next\",command=next_page)\n",
    "next_button.pack(side=tk.LEFT)\n",
    "\n",
    "# Bind the \"Ask\" button and enter key press to the ask_question function\n",
    "ask_button.config(command=ask_question)\n",
    "question_text.bind(\"<KeyPress>\", handle_keypress)\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
